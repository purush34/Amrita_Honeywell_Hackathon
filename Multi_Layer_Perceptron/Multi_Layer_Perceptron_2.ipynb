{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Quality Classification using Muti Layer Perceptron (Dataset 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook focusses on developing a Multi Layer perceptron which classifies a particular power signal into its respective power quality condition. The dataset used here contains signals which belong to one of the 6 classes(power quality condition). The sampling rate of this data is 256. This means that each signal is characterized by 256 data points. Here the signals provided are in time domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from scipy.fft import fft,fftfreq\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset using pandas\n",
    "x_train = pd.read_csv(\"../Dataset2/Train/Voltage_L1_train.csv\")\n",
    "y_train = pd.read_csv(\"../Dataset2/Train/output_train.csv\")\n",
    "x_test = pd.read_csv(\"../Dataset2/Test/Voltage_L1_test.csv\")\n",
    "y_test = pd.read_csv(\"../Dataset2/Test/output_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (5999, 256)\n",
      "y_train (5999, 1)\n",
      "x_test (3599, 256)\n",
      "y_test (3599, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train\",x_train.shape)\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"x_test\",x_test.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This segment of notebook contains all the preprocessing steps which are performed on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropna() function is used to remove all those rows which contains NA values\n",
    "x_train.dropna(axis=0,inplace=True)\n",
    "y_train.dropna(axis=0,inplace=True)\n",
    "x_test.dropna(axis=0,inplace=True)\n",
    "y_test.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (5999, 256)\n",
      "y_train (5999, 1)\n",
      "x_test (3599, 256)\n",
      "y_test (3599, 1)\n"
     ]
    }
   ],
   "source": [
    "#shape of the data frame after dropping the rows containing NA values\n",
    "print(\"x_train\",x_train.shape)\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"x_test\",x_test.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are constructing the array which will finally contain the column names\n",
    "header =[]\n",
    "for i in range(1,x_train.shape[1]+1):\n",
    "    header.append(\"Col\"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the column name array to the respectinve dataframes\n",
    "x_train.columns = header\n",
    "x_test.columns = header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the column name array to the respectinve dataframes\n",
    "header = [\"output\"]\n",
    "y_train.columns = header\n",
    "y_test.columns = header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "      <th>...</th>\n",
       "      <th>Col247</th>\n",
       "      <th>Col248</th>\n",
       "      <th>Col249</th>\n",
       "      <th>Col250</th>\n",
       "      <th>Col251</th>\n",
       "      <th>Col252</th>\n",
       "      <th>Col253</th>\n",
       "      <th>Col254</th>\n",
       "      <th>Col255</th>\n",
       "      <th>Col256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>573.652486</td>\n",
       "      <td>1003.343736</td>\n",
       "      <td>1588.404525</td>\n",
       "      <td>2317.576741</td>\n",
       "      <td>2804.364311</td>\n",
       "      <td>3225.322510</td>\n",
       "      <td>3662.821690</td>\n",
       "      <td>4174.627969</td>\n",
       "      <td>4656.244143</td>\n",
       "      <td>4939.070130</td>\n",
       "      <td>...</td>\n",
       "      <td>-4650.282434</td>\n",
       "      <td>-4228.581226</td>\n",
       "      <td>-3865.609932</td>\n",
       "      <td>-3395.654756</td>\n",
       "      <td>-2933.680470</td>\n",
       "      <td>-2322.450904</td>\n",
       "      <td>-1841.562453</td>\n",
       "      <td>-1282.042025</td>\n",
       "      <td>-601.968217</td>\n",
       "      <td>-156.848367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4757.365183</td>\n",
       "      <td>5264.598912</td>\n",
       "      <td>5428.642486</td>\n",
       "      <td>5650.413073</td>\n",
       "      <td>5939.710012</td>\n",
       "      <td>5911.948067</td>\n",
       "      <td>6147.642171</td>\n",
       "      <td>6076.921501</td>\n",
       "      <td>5958.797444</td>\n",
       "      <td>6053.817701</td>\n",
       "      <td>...</td>\n",
       "      <td>-280.360872</td>\n",
       "      <td>323.325836</td>\n",
       "      <td>861.103019</td>\n",
       "      <td>1415.929276</td>\n",
       "      <td>2007.692919</td>\n",
       "      <td>2561.130303</td>\n",
       "      <td>2960.282598</td>\n",
       "      <td>3619.932691</td>\n",
       "      <td>4008.288701</td>\n",
       "      <td>4422.229911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4242.144824</td>\n",
       "      <td>4644.679402</td>\n",
       "      <td>5013.356532</td>\n",
       "      <td>5229.417051</td>\n",
       "      <td>5534.898007</td>\n",
       "      <td>5797.190678</td>\n",
       "      <td>5930.658682</td>\n",
       "      <td>5960.014599</td>\n",
       "      <td>6055.336310</td>\n",
       "      <td>6103.707793</td>\n",
       "      <td>...</td>\n",
       "      <td>-1256.270585</td>\n",
       "      <td>-616.527428</td>\n",
       "      <td>-67.068193</td>\n",
       "      <td>549.016676</td>\n",
       "      <td>1099.652199</td>\n",
       "      <td>1697.572166</td>\n",
       "      <td>2239.961604</td>\n",
       "      <td>2776.876479</td>\n",
       "      <td>3248.638662</td>\n",
       "      <td>3807.665149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2077.819247</td>\n",
       "      <td>2561.679246</td>\n",
       "      <td>3085.653813</td>\n",
       "      <td>3545.905160</td>\n",
       "      <td>4023.421592</td>\n",
       "      <td>4496.705157</td>\n",
       "      <td>4809.079868</td>\n",
       "      <td>5186.298840</td>\n",
       "      <td>5453.627533</td>\n",
       "      <td>5737.354699</td>\n",
       "      <td>...</td>\n",
       "      <td>-3557.345152</td>\n",
       "      <td>-3017.951179</td>\n",
       "      <td>-2596.647329</td>\n",
       "      <td>-1996.266675</td>\n",
       "      <td>-1467.203661</td>\n",
       "      <td>-885.101101</td>\n",
       "      <td>-329.685256</td>\n",
       "      <td>304.222722</td>\n",
       "      <td>935.528504</td>\n",
       "      <td>1460.127297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3599.645319</td>\n",
       "      <td>4099.944762</td>\n",
       "      <td>4499.282469</td>\n",
       "      <td>4897.875855</td>\n",
       "      <td>5120.077118</td>\n",
       "      <td>5402.227743</td>\n",
       "      <td>5694.801362</td>\n",
       "      <td>5928.683099</td>\n",
       "      <td>5981.616502</td>\n",
       "      <td>6052.006904</td>\n",
       "      <td>...</td>\n",
       "      <td>-2020.240712</td>\n",
       "      <td>-1388.704968</td>\n",
       "      <td>-849.731284</td>\n",
       "      <td>-232.632694</td>\n",
       "      <td>341.406093</td>\n",
       "      <td>854.579135</td>\n",
       "      <td>1528.023058</td>\n",
       "      <td>2002.557438</td>\n",
       "      <td>2576.468343</td>\n",
       "      <td>3036.303600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Col1         Col2         Col3         Col4         Col5  \\\n",
       "0   573.652486  1003.343736  1588.404525  2317.576741  2804.364311   \n",
       "1  4757.365183  5264.598912  5428.642486  5650.413073  5939.710012   \n",
       "2  4242.144824  4644.679402  5013.356532  5229.417051  5534.898007   \n",
       "3  2077.819247  2561.679246  3085.653813  3545.905160  4023.421592   \n",
       "4  3599.645319  4099.944762  4499.282469  4897.875855  5120.077118   \n",
       "\n",
       "          Col6         Col7         Col8         Col9        Col10  ...  \\\n",
       "0  3225.322510  3662.821690  4174.627969  4656.244143  4939.070130  ...   \n",
       "1  5911.948067  6147.642171  6076.921501  5958.797444  6053.817701  ...   \n",
       "2  5797.190678  5930.658682  5960.014599  6055.336310  6103.707793  ...   \n",
       "3  4496.705157  4809.079868  5186.298840  5453.627533  5737.354699  ...   \n",
       "4  5402.227743  5694.801362  5928.683099  5981.616502  6052.006904  ...   \n",
       "\n",
       "        Col247       Col248       Col249       Col250       Col251  \\\n",
       "0 -4650.282434 -4228.581226 -3865.609932 -3395.654756 -2933.680470   \n",
       "1  -280.360872   323.325836   861.103019  1415.929276  2007.692919   \n",
       "2 -1256.270585  -616.527428   -67.068193   549.016676  1099.652199   \n",
       "3 -3557.345152 -3017.951179 -2596.647329 -1996.266675 -1467.203661   \n",
       "4 -2020.240712 -1388.704968  -849.731284  -232.632694   341.406093   \n",
       "\n",
       "        Col252       Col253       Col254       Col255       Col256  \n",
       "0 -2322.450904 -1841.562453 -1282.042025  -601.968217  -156.848367  \n",
       "1  2561.130303  2960.282598  3619.932691  4008.288701  4422.229911  \n",
       "2  1697.572166  2239.961604  2776.876479  3248.638662  3807.665149  \n",
       "3  -885.101101  -329.685256   304.222722   935.528504  1460.127297  \n",
       "4   854.579135  1528.023058  2002.557438  2576.468343  3036.303600  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "      <th>...</th>\n",
       "      <th>Col247</th>\n",
       "      <th>Col248</th>\n",
       "      <th>Col249</th>\n",
       "      <th>Col250</th>\n",
       "      <th>Col251</th>\n",
       "      <th>Col252</th>\n",
       "      <th>Col253</th>\n",
       "      <th>Col254</th>\n",
       "      <th>Col255</th>\n",
       "      <th>Col256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4216.164293</td>\n",
       "      <td>4550.919227</td>\n",
       "      <td>4885.253969</td>\n",
       "      <td>5265.577080</td>\n",
       "      <td>5634.058181</td>\n",
       "      <td>5690.878844</td>\n",
       "      <td>5984.805444</td>\n",
       "      <td>6083.124480</td>\n",
       "      <td>6024.018340</td>\n",
       "      <td>6144.339029</td>\n",
       "      <td>...</td>\n",
       "      <td>-1279.720481</td>\n",
       "      <td>-672.204610</td>\n",
       "      <td>-35.247405</td>\n",
       "      <td>565.001817</td>\n",
       "      <td>1139.580709</td>\n",
       "      <td>1623.258946</td>\n",
       "      <td>2159.189259</td>\n",
       "      <td>2729.066018</td>\n",
       "      <td>3292.437301</td>\n",
       "      <td>3770.985050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>795.638794</td>\n",
       "      <td>1340.736614</td>\n",
       "      <td>1928.805243</td>\n",
       "      <td>2465.916079</td>\n",
       "      <td>3009.942949</td>\n",
       "      <td>3475.153730</td>\n",
       "      <td>3938.568022</td>\n",
       "      <td>4372.781654</td>\n",
       "      <td>4765.603003</td>\n",
       "      <td>5090.817748</td>\n",
       "      <td>...</td>\n",
       "      <td>-4525.083123</td>\n",
       "      <td>-4077.498908</td>\n",
       "      <td>-3630.262875</td>\n",
       "      <td>-3176.648183</td>\n",
       "      <td>-2652.563485</td>\n",
       "      <td>-2135.982927</td>\n",
       "      <td>-1549.968773</td>\n",
       "      <td>-970.063115</td>\n",
       "      <td>-413.973048</td>\n",
       "      <td>202.507328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1220.943267</td>\n",
       "      <td>1770.550513</td>\n",
       "      <td>2318.816674</td>\n",
       "      <td>2850.186275</td>\n",
       "      <td>3357.786987</td>\n",
       "      <td>3848.017230</td>\n",
       "      <td>4274.339651</td>\n",
       "      <td>4669.175893</td>\n",
       "      <td>5027.840955</td>\n",
       "      <td>5329.856655</td>\n",
       "      <td>...</td>\n",
       "      <td>-4214.790563</td>\n",
       "      <td>-3762.024055</td>\n",
       "      <td>-3303.182589</td>\n",
       "      <td>-2802.950592</td>\n",
       "      <td>-2246.516780</td>\n",
       "      <td>-1712.153266</td>\n",
       "      <td>-1120.729328</td>\n",
       "      <td>-553.276475</td>\n",
       "      <td>43.863168</td>\n",
       "      <td>614.870963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1013.772210</td>\n",
       "      <td>1621.783618</td>\n",
       "      <td>2178.146635</td>\n",
       "      <td>2733.460484</td>\n",
       "      <td>3178.151416</td>\n",
       "      <td>3692.797702</td>\n",
       "      <td>4177.895304</td>\n",
       "      <td>4539.640464</td>\n",
       "      <td>4948.873847</td>\n",
       "      <td>5271.862849</td>\n",
       "      <td>...</td>\n",
       "      <td>-4371.401183</td>\n",
       "      <td>-3937.075334</td>\n",
       "      <td>-3502.317297</td>\n",
       "      <td>-2922.179500</td>\n",
       "      <td>-2467.320667</td>\n",
       "      <td>-1904.033355</td>\n",
       "      <td>-1362.385474</td>\n",
       "      <td>-704.032900</td>\n",
       "      <td>-188.518269</td>\n",
       "      <td>466.064827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4490.355896</td>\n",
       "      <td>4862.601717</td>\n",
       "      <td>5235.681699</td>\n",
       "      <td>5401.432840</td>\n",
       "      <td>5741.255908</td>\n",
       "      <td>5840.507807</td>\n",
       "      <td>6030.352157</td>\n",
       "      <td>6037.480783</td>\n",
       "      <td>6109.355580</td>\n",
       "      <td>6000.190091</td>\n",
       "      <td>...</td>\n",
       "      <td>-848.410798</td>\n",
       "      <td>-279.507713</td>\n",
       "      <td>269.777288</td>\n",
       "      <td>853.806015</td>\n",
       "      <td>1410.187144</td>\n",
       "      <td>1977.999116</td>\n",
       "      <td>2621.735468</td>\n",
       "      <td>3069.781180</td>\n",
       "      <td>3624.993700</td>\n",
       "      <td>4116.325633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Col1         Col2         Col3         Col4         Col5  \\\n",
       "0  4216.164293  4550.919227  4885.253969  5265.577080  5634.058181   \n",
       "1   795.638794  1340.736614  1928.805243  2465.916079  3009.942949   \n",
       "2  1220.943267  1770.550513  2318.816674  2850.186275  3357.786987   \n",
       "3  1013.772210  1621.783618  2178.146635  2733.460484  3178.151416   \n",
       "4  4490.355896  4862.601717  5235.681699  5401.432840  5741.255908   \n",
       "\n",
       "          Col6         Col7         Col8         Col9        Col10  ...  \\\n",
       "0  5690.878844  5984.805444  6083.124480  6024.018340  6144.339029  ...   \n",
       "1  3475.153730  3938.568022  4372.781654  4765.603003  5090.817748  ...   \n",
       "2  3848.017230  4274.339651  4669.175893  5027.840955  5329.856655  ...   \n",
       "3  3692.797702  4177.895304  4539.640464  4948.873847  5271.862849  ...   \n",
       "4  5840.507807  6030.352157  6037.480783  6109.355580  6000.190091  ...   \n",
       "\n",
       "        Col247       Col248       Col249       Col250       Col251  \\\n",
       "0 -1279.720481  -672.204610   -35.247405   565.001817  1139.580709   \n",
       "1 -4525.083123 -4077.498908 -3630.262875 -3176.648183 -2652.563485   \n",
       "2 -4214.790563 -3762.024055 -3303.182589 -2802.950592 -2246.516780   \n",
       "3 -4371.401183 -3937.075334 -3502.317297 -2922.179500 -2467.320667   \n",
       "4  -848.410798  -279.507713   269.777288   853.806015  1410.187144   \n",
       "\n",
       "        Col252       Col253       Col254       Col255       Col256  \n",
       "0  1623.258946  2159.189259  2729.066018  3292.437301  3770.985050  \n",
       "1 -2135.982927 -1549.968773  -970.063115  -413.973048   202.507328  \n",
       "2 -1712.153266 -1120.729328  -553.276475    43.863168   614.870963  \n",
       "3 -1904.033355 -1362.385474  -704.032900  -188.518269   466.064827  \n",
       "4  1977.999116  2621.735468  3069.781180  3624.993700  4116.325633  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   output\n",
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   output\n",
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are splitting the training set in the ratio of 70%,30% (training set,validation set)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dummies function is used here to perform one hot encoding of the y_* numpy arrays\n",
    "y_train_hot = pd.get_dummies(y_train['output'])\n",
    "y_test_hot = pd.get_dummies(y_test['output'])\n",
    "y_val_hot = pd.get_dummies(y_val['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3256</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1  2  3  4  5  6\n",
       "927   1  0  0  0  0  0\n",
       "3256  0  0  0  1  0  0\n",
       "45    1  0  0  0  0  0\n",
       "1260  0  1  0  0  0  0\n",
       "1096  0  1  0  0  0  0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_hot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data transformation steps employed here are as follows:<br>\n",
    "\n",
    "1) Fourier Transform<br>\n",
    "2) Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are overwritting the dataframe with the respective waves which we obtained after doing fourier \n",
    "#transformation\n",
    "for i in range(0,x_train.shape[0]):\n",
    "    x_train[i][:] = np.abs(fft(x_train[i][:]))\n",
    "    \n",
    "for i in range(0,x_test.shape[0]):\n",
    "    x_test[i][:] = np.abs(fft(x_test[i][:]))\n",
    "\n",
    "for i in range(0,x_val.shape[0]):\n",
    "    x_val[i][:] = np.abs(fft(x_val[i][:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transform = StandardScaler()\\nx_train_tr = transform.fit_transform(x_train)\\nx_test_tr = transform.fit_transform(x_test)\\nx_val_tr = transform.fit_transform(x_val)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we are performing normalization\n",
    "'''transform = StandardScaler()\n",
    "x_train_tr = transform.fit_transform(x_train)\n",
    "x_test_tr = transform.fit_transform(x_test)\n",
    "x_val_tr = transform.fit_transform(x_val)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tr = np.log(x_train)\n",
    "x_test_tr = np.log(x_test)\n",
    "x_val_tr = np.log(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (4199, 256)\n",
      "(4199, 6)\n",
      "Validation (1800, 256)\n",
      "(1800, 6)\n",
      "Test (3599, 256)\n",
      "(3599, 6)\n"
     ]
    }
   ],
   "source": [
    "#final dimensions of the data\n",
    "print(\"Training\",x_train_tr.shape)\n",
    "print(y_train_hot.shape)\n",
    "print(\"Validation\",x_val_tr.shape)\n",
    "print(y_val_hot.shape)\n",
    "print(\"Test\",x_test_tr.shape)\n",
    "print(y_test_hot.shape)\n",
    "sampling_rate = x_train_tr.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(no_of_classes,sampling_rate):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(64, input_shape=(sampling_rate,), activation = 'relu'))\n",
    "    model.add(Dense(32, activation = 'relu'))\n",
    "    #model.add(Dropout(0.6))\n",
    "    model.add(Dense(16, activation = 'relu'))\n",
    "    #model.add(Dropout(0.6))\n",
    "    model.add(Dense(no_of_classes, activation = 'softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 1.9535 - accuracy: 0.2038 - val_loss: 1.4631 - val_accuracy: 0.5583\n",
      "Epoch 2/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.3992 - accuracy: 0.5062 - val_loss: 1.0827 - val_accuracy: 0.7094\n",
      "Epoch 3/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.9759 - accuracy: 0.7172 - val_loss: 0.7684 - val_accuracy: 0.7800\n",
      "Epoch 4/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.6717 - accuracy: 0.8410 - val_loss: 0.5139 - val_accuracy: 0.9039\n",
      "Epoch 5/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.8979 - val_loss: 0.3124 - val_accuracy: 0.9400\n",
      "Epoch 6/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.9115 - val_loss: 0.3318 - val_accuracy: 0.8844\n",
      "Epoch 7/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2522 - accuracy: 0.9267 - val_loss: 0.1783 - val_accuracy: 0.9706\n",
      "Epoch 8/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1656 - accuracy: 0.9725 - val_loss: 0.1684 - val_accuracy: 0.9550\n",
      "Epoch 9/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9761 - val_loss: 0.1153 - val_accuracy: 0.9883\n",
      "Epoch 10/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1074 - accuracy: 0.9828 - val_loss: 0.0794 - val_accuracy: 0.9906\n",
      "Epoch 11/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1011 - accuracy: 0.9791 - val_loss: 0.0610 - val_accuracy: 0.9939\n",
      "Epoch 12/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0716 - accuracy: 0.9865 - val_loss: 0.0609 - val_accuracy: 0.9906\n",
      "Epoch 13/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9850 - val_loss: 0.0573 - val_accuracy: 0.9900\n",
      "Epoch 14/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.9875 - val_loss: 0.0403 - val_accuracy: 0.9961\n",
      "Epoch 15/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9902 - val_loss: 0.0361 - val_accuracy: 0.9956\n",
      "Epoch 16/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9935 - val_loss: 0.0401 - val_accuracy: 0.9950\n",
      "Epoch 17/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9875 - val_loss: 0.0215 - val_accuracy: 0.9983\n",
      "Epoch 18/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9895 - val_loss: 0.0191 - val_accuracy: 0.9989\n",
      "Epoch 19/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9851 - val_loss: 0.0169 - val_accuracy: 0.9983\n",
      "Epoch 20/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9947 - val_loss: 0.0332 - val_accuracy: 0.9906\n",
      "Epoch 21/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.9967 - val_loss: 0.0421 - val_accuracy: 0.9889\n",
      "Epoch 22/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9863 - val_loss: 0.0181 - val_accuracy: 0.9961\n",
      "Epoch 23/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 0.9943 - val_loss: 0.0165 - val_accuracy: 0.9967\n",
      "Epoch 24/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 0.9940 - val_loss: 0.0231 - val_accuracy: 0.9961\n",
      "Epoch 25/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9907 - val_loss: 0.0114 - val_accuracy: 0.9989\n",
      "Epoch 26/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.9966 - val_loss: 0.0148 - val_accuracy: 0.9956\n",
      "Epoch 27/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.0161 - val_accuracy: 0.9950\n",
      "Epoch 28/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.9950 - val_loss: 0.0207 - val_accuracy: 0.9944\n",
      "Epoch 29/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.9880 - val_loss: 0.0084 - val_accuracy: 0.9994\n",
      "Epoch 30/30\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.9956 - val_loss: 0.0154 - val_accuracy: 0.9944\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_dir = \"logs2/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model = model_training(6,sampling_rate)\n",
    "history = model.fit(x_train_tr, y_train_hot, batch_size=64, epochs=30, validation_data=(x_val_tr, y_val_hot), callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 206856), started 1:54:57 ago. (Use '!kill 206856' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-115c39799a04417a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-115c39799a04417a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs2/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 19,158\n",
      "Trainable params: 19,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min val: 0.5583333373069763\n",
      "avg val 0.9527777791023254\n",
      "max val: 0.9994444251060486\n",
      "\n",
      "min train: 0.28792569041252136\n",
      "avg train 0.9302770525217057\n",
      "max train: 0.9969040155410767\n"
     ]
    }
   ],
   "source": [
    "print(\"min val:\",min(history.history['val_accuracy']))\n",
    "print(\"avg val\",np.mean(history.history['val_accuracy']) )\n",
    "print(\"max val:\",max(history.history['val_accuracy']))\n",
    "print()\n",
    "print(\"min train:\",min(history.history['accuracy']))\n",
    "print(\"avg train\",np.mean(history.history['accuracy']) )\n",
    "print(\"max train:\",max(history.history['accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 460us/step - loss: 0.0256 - accuracy: 0.9933\n",
      "Test accuracy is [0.02559136226773262, 0.9933314919471741]\n"
     ]
    }
   ],
   "source": [
    "pred_acc = model.evaluate(x_test_tr,y_test_hot)\n",
    "print(\"Test accuracy is {}\".format(pred_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = confusion_matrix(y_test_hot.to_numpy().argmax(axis=1), model.predict(x_test_tr).argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[599,   0,   0,   0,   0,   0],\n",
       "       [  0, 600,   0,   0,   0,   0],\n",
       "       [ 24,   0, 576,   0,   0,   0],\n",
       "       [  0,   0,   0, 600,   0,   0],\n",
       "       [  0,   0,   0,   0, 600,   0],\n",
       "       [  0,   0,   0,   0,   0, 600]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "to_cm = pd.DataFrame(array, index = [i for i in [\"Type-1\",\"Type-2\",\"Type-3\",\"Type-4\",\"Type-5\",\"Type-6\"]],\n",
    "                  columns = [i for i in [\"Type-1\",\"Type-2\",\"Type-3\",\"Type-4\",\"Type-5\",\"Type-6\"]])\n",
    "plt.figure(figsize = (13,9))\n",
    "sn.heatmap(to_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"model1.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
