{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Quality Classification using Muti Layer Perceptron (Dataset 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook focusses on developing a Multi Layer perceptron which classifies a particular power signal into its respective power quality condition. The dataset used here contains signals which belong to one of the 6 classes(power quality condition). The sampling rate of this data is 256. This means that each signal is characterized by 256 data points. Here the signals provided are in time domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from scipy.fft import fft,fftfreq\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset using pandas\n",
    "x_train = pd.read_csv(\"../Dataset2/Train/Voltage_L1_train.csv\")\n",
    "y_train = pd.read_csv(\"../Dataset2/Train/output_train.csv\")\n",
    "x_test = pd.read_csv(\"../Dataset2/Test/Voltage_L1_test.csv\")\n",
    "y_test = pd.read_csv(\"../Dataset2/Test/output_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (5999, 256)\n",
      "y_train (5999, 1)\n",
      "x_test (3599, 256)\n",
      "y_test (3599, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train\",x_train.shape)\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"x_test\",x_test.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This segment of notebook contains all the preprocessing steps which are performed on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropna() function is used to remove all those rows which contains NA values\n",
    "x_train.dropna(axis=0,inplace=True)\n",
    "y_train.dropna(axis=0,inplace=True)\n",
    "x_test.dropna(axis=0,inplace=True)\n",
    "y_test.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (5999, 256)\n",
      "y_train (5999, 1)\n",
      "x_test (3599, 256)\n",
      "y_test (3599, 1)\n"
     ]
    }
   ],
   "source": [
    "#shape of the data frame after dropping the rows containing NA values\n",
    "print(\"x_train\",x_train.shape)\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"x_test\",x_test.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are constructing the array which will finally contain the column names\n",
    "header =[]\n",
    "for i in range(1,x_train.shape[1]+1):\n",
    "    header.append(\"Col\"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the column name array to the respectinve dataframes\n",
    "x_train.columns = header\n",
    "x_test.columns = header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the column name array to the respectinve dataframes\n",
    "header = [\"output\"]\n",
    "y_train.columns = header\n",
    "y_test.columns = header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "      <th>...</th>\n",
       "      <th>Col247</th>\n",
       "      <th>Col248</th>\n",
       "      <th>Col249</th>\n",
       "      <th>Col250</th>\n",
       "      <th>Col251</th>\n",
       "      <th>Col252</th>\n",
       "      <th>Col253</th>\n",
       "      <th>Col254</th>\n",
       "      <th>Col255</th>\n",
       "      <th>Col256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>573.652486</td>\n",
       "      <td>1003.343736</td>\n",
       "      <td>1588.404525</td>\n",
       "      <td>2317.576741</td>\n",
       "      <td>2804.364311</td>\n",
       "      <td>3225.322510</td>\n",
       "      <td>3662.821690</td>\n",
       "      <td>4174.627969</td>\n",
       "      <td>4656.244143</td>\n",
       "      <td>4939.070130</td>\n",
       "      <td>...</td>\n",
       "      <td>-4650.282434</td>\n",
       "      <td>-4228.581226</td>\n",
       "      <td>-3865.609932</td>\n",
       "      <td>-3395.654756</td>\n",
       "      <td>-2933.680470</td>\n",
       "      <td>-2322.450904</td>\n",
       "      <td>-1841.562453</td>\n",
       "      <td>-1282.042025</td>\n",
       "      <td>-601.968217</td>\n",
       "      <td>-156.848367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4757.365183</td>\n",
       "      <td>5264.598912</td>\n",
       "      <td>5428.642486</td>\n",
       "      <td>5650.413073</td>\n",
       "      <td>5939.710012</td>\n",
       "      <td>5911.948067</td>\n",
       "      <td>6147.642171</td>\n",
       "      <td>6076.921501</td>\n",
       "      <td>5958.797444</td>\n",
       "      <td>6053.817701</td>\n",
       "      <td>...</td>\n",
       "      <td>-280.360872</td>\n",
       "      <td>323.325836</td>\n",
       "      <td>861.103019</td>\n",
       "      <td>1415.929276</td>\n",
       "      <td>2007.692919</td>\n",
       "      <td>2561.130303</td>\n",
       "      <td>2960.282598</td>\n",
       "      <td>3619.932691</td>\n",
       "      <td>4008.288701</td>\n",
       "      <td>4422.229911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4242.144824</td>\n",
       "      <td>4644.679402</td>\n",
       "      <td>5013.356532</td>\n",
       "      <td>5229.417051</td>\n",
       "      <td>5534.898007</td>\n",
       "      <td>5797.190678</td>\n",
       "      <td>5930.658682</td>\n",
       "      <td>5960.014599</td>\n",
       "      <td>6055.336310</td>\n",
       "      <td>6103.707793</td>\n",
       "      <td>...</td>\n",
       "      <td>-1256.270585</td>\n",
       "      <td>-616.527428</td>\n",
       "      <td>-67.068193</td>\n",
       "      <td>549.016676</td>\n",
       "      <td>1099.652199</td>\n",
       "      <td>1697.572166</td>\n",
       "      <td>2239.961604</td>\n",
       "      <td>2776.876479</td>\n",
       "      <td>3248.638662</td>\n",
       "      <td>3807.665149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2077.819247</td>\n",
       "      <td>2561.679246</td>\n",
       "      <td>3085.653813</td>\n",
       "      <td>3545.905160</td>\n",
       "      <td>4023.421592</td>\n",
       "      <td>4496.705157</td>\n",
       "      <td>4809.079868</td>\n",
       "      <td>5186.298840</td>\n",
       "      <td>5453.627533</td>\n",
       "      <td>5737.354699</td>\n",
       "      <td>...</td>\n",
       "      <td>-3557.345152</td>\n",
       "      <td>-3017.951179</td>\n",
       "      <td>-2596.647329</td>\n",
       "      <td>-1996.266675</td>\n",
       "      <td>-1467.203661</td>\n",
       "      <td>-885.101101</td>\n",
       "      <td>-329.685256</td>\n",
       "      <td>304.222722</td>\n",
       "      <td>935.528504</td>\n",
       "      <td>1460.127297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3599.645319</td>\n",
       "      <td>4099.944762</td>\n",
       "      <td>4499.282469</td>\n",
       "      <td>4897.875855</td>\n",
       "      <td>5120.077118</td>\n",
       "      <td>5402.227743</td>\n",
       "      <td>5694.801362</td>\n",
       "      <td>5928.683099</td>\n",
       "      <td>5981.616502</td>\n",
       "      <td>6052.006904</td>\n",
       "      <td>...</td>\n",
       "      <td>-2020.240712</td>\n",
       "      <td>-1388.704968</td>\n",
       "      <td>-849.731284</td>\n",
       "      <td>-232.632694</td>\n",
       "      <td>341.406093</td>\n",
       "      <td>854.579135</td>\n",
       "      <td>1528.023058</td>\n",
       "      <td>2002.557438</td>\n",
       "      <td>2576.468343</td>\n",
       "      <td>3036.303600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Col1         Col2         Col3         Col4         Col5  \\\n",
       "0   573.652486  1003.343736  1588.404525  2317.576741  2804.364311   \n",
       "1  4757.365183  5264.598912  5428.642486  5650.413073  5939.710012   \n",
       "2  4242.144824  4644.679402  5013.356532  5229.417051  5534.898007   \n",
       "3  2077.819247  2561.679246  3085.653813  3545.905160  4023.421592   \n",
       "4  3599.645319  4099.944762  4499.282469  4897.875855  5120.077118   \n",
       "\n",
       "          Col6         Col7         Col8         Col9        Col10  ...  \\\n",
       "0  3225.322510  3662.821690  4174.627969  4656.244143  4939.070130  ...   \n",
       "1  5911.948067  6147.642171  6076.921501  5958.797444  6053.817701  ...   \n",
       "2  5797.190678  5930.658682  5960.014599  6055.336310  6103.707793  ...   \n",
       "3  4496.705157  4809.079868  5186.298840  5453.627533  5737.354699  ...   \n",
       "4  5402.227743  5694.801362  5928.683099  5981.616502  6052.006904  ...   \n",
       "\n",
       "        Col247       Col248       Col249       Col250       Col251  \\\n",
       "0 -4650.282434 -4228.581226 -3865.609932 -3395.654756 -2933.680470   \n",
       "1  -280.360872   323.325836   861.103019  1415.929276  2007.692919   \n",
       "2 -1256.270585  -616.527428   -67.068193   549.016676  1099.652199   \n",
       "3 -3557.345152 -3017.951179 -2596.647329 -1996.266675 -1467.203661   \n",
       "4 -2020.240712 -1388.704968  -849.731284  -232.632694   341.406093   \n",
       "\n",
       "        Col252       Col253       Col254       Col255       Col256  \n",
       "0 -2322.450904 -1841.562453 -1282.042025  -601.968217  -156.848367  \n",
       "1  2561.130303  2960.282598  3619.932691  4008.288701  4422.229911  \n",
       "2  1697.572166  2239.961604  2776.876479  3248.638662  3807.665149  \n",
       "3  -885.101101  -329.685256   304.222722   935.528504  1460.127297  \n",
       "4   854.579135  1528.023058  2002.557438  2576.468343  3036.303600  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "      <th>...</th>\n",
       "      <th>Col247</th>\n",
       "      <th>Col248</th>\n",
       "      <th>Col249</th>\n",
       "      <th>Col250</th>\n",
       "      <th>Col251</th>\n",
       "      <th>Col252</th>\n",
       "      <th>Col253</th>\n",
       "      <th>Col254</th>\n",
       "      <th>Col255</th>\n",
       "      <th>Col256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4216.164293</td>\n",
       "      <td>4550.919227</td>\n",
       "      <td>4885.253969</td>\n",
       "      <td>5265.577080</td>\n",
       "      <td>5634.058181</td>\n",
       "      <td>5690.878844</td>\n",
       "      <td>5984.805444</td>\n",
       "      <td>6083.124480</td>\n",
       "      <td>6024.018340</td>\n",
       "      <td>6144.339029</td>\n",
       "      <td>...</td>\n",
       "      <td>-1279.720481</td>\n",
       "      <td>-672.204610</td>\n",
       "      <td>-35.247405</td>\n",
       "      <td>565.001817</td>\n",
       "      <td>1139.580709</td>\n",
       "      <td>1623.258946</td>\n",
       "      <td>2159.189259</td>\n",
       "      <td>2729.066018</td>\n",
       "      <td>3292.437301</td>\n",
       "      <td>3770.985050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>795.638794</td>\n",
       "      <td>1340.736614</td>\n",
       "      <td>1928.805243</td>\n",
       "      <td>2465.916079</td>\n",
       "      <td>3009.942949</td>\n",
       "      <td>3475.153730</td>\n",
       "      <td>3938.568022</td>\n",
       "      <td>4372.781654</td>\n",
       "      <td>4765.603003</td>\n",
       "      <td>5090.817748</td>\n",
       "      <td>...</td>\n",
       "      <td>-4525.083123</td>\n",
       "      <td>-4077.498908</td>\n",
       "      <td>-3630.262875</td>\n",
       "      <td>-3176.648183</td>\n",
       "      <td>-2652.563485</td>\n",
       "      <td>-2135.982927</td>\n",
       "      <td>-1549.968773</td>\n",
       "      <td>-970.063115</td>\n",
       "      <td>-413.973048</td>\n",
       "      <td>202.507328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1220.943267</td>\n",
       "      <td>1770.550513</td>\n",
       "      <td>2318.816674</td>\n",
       "      <td>2850.186275</td>\n",
       "      <td>3357.786987</td>\n",
       "      <td>3848.017230</td>\n",
       "      <td>4274.339651</td>\n",
       "      <td>4669.175893</td>\n",
       "      <td>5027.840955</td>\n",
       "      <td>5329.856655</td>\n",
       "      <td>...</td>\n",
       "      <td>-4214.790563</td>\n",
       "      <td>-3762.024055</td>\n",
       "      <td>-3303.182589</td>\n",
       "      <td>-2802.950592</td>\n",
       "      <td>-2246.516780</td>\n",
       "      <td>-1712.153266</td>\n",
       "      <td>-1120.729328</td>\n",
       "      <td>-553.276475</td>\n",
       "      <td>43.863168</td>\n",
       "      <td>614.870963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1013.772210</td>\n",
       "      <td>1621.783618</td>\n",
       "      <td>2178.146635</td>\n",
       "      <td>2733.460484</td>\n",
       "      <td>3178.151416</td>\n",
       "      <td>3692.797702</td>\n",
       "      <td>4177.895304</td>\n",
       "      <td>4539.640464</td>\n",
       "      <td>4948.873847</td>\n",
       "      <td>5271.862849</td>\n",
       "      <td>...</td>\n",
       "      <td>-4371.401183</td>\n",
       "      <td>-3937.075334</td>\n",
       "      <td>-3502.317297</td>\n",
       "      <td>-2922.179500</td>\n",
       "      <td>-2467.320667</td>\n",
       "      <td>-1904.033355</td>\n",
       "      <td>-1362.385474</td>\n",
       "      <td>-704.032900</td>\n",
       "      <td>-188.518269</td>\n",
       "      <td>466.064827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4490.355896</td>\n",
       "      <td>4862.601717</td>\n",
       "      <td>5235.681699</td>\n",
       "      <td>5401.432840</td>\n",
       "      <td>5741.255908</td>\n",
       "      <td>5840.507807</td>\n",
       "      <td>6030.352157</td>\n",
       "      <td>6037.480783</td>\n",
       "      <td>6109.355580</td>\n",
       "      <td>6000.190091</td>\n",
       "      <td>...</td>\n",
       "      <td>-848.410798</td>\n",
       "      <td>-279.507713</td>\n",
       "      <td>269.777288</td>\n",
       "      <td>853.806015</td>\n",
       "      <td>1410.187144</td>\n",
       "      <td>1977.999116</td>\n",
       "      <td>2621.735468</td>\n",
       "      <td>3069.781180</td>\n",
       "      <td>3624.993700</td>\n",
       "      <td>4116.325633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Col1         Col2         Col3         Col4         Col5  \\\n",
       "0  4216.164293  4550.919227  4885.253969  5265.577080  5634.058181   \n",
       "1   795.638794  1340.736614  1928.805243  2465.916079  3009.942949   \n",
       "2  1220.943267  1770.550513  2318.816674  2850.186275  3357.786987   \n",
       "3  1013.772210  1621.783618  2178.146635  2733.460484  3178.151416   \n",
       "4  4490.355896  4862.601717  5235.681699  5401.432840  5741.255908   \n",
       "\n",
       "          Col6         Col7         Col8         Col9        Col10  ...  \\\n",
       "0  5690.878844  5984.805444  6083.124480  6024.018340  6144.339029  ...   \n",
       "1  3475.153730  3938.568022  4372.781654  4765.603003  5090.817748  ...   \n",
       "2  3848.017230  4274.339651  4669.175893  5027.840955  5329.856655  ...   \n",
       "3  3692.797702  4177.895304  4539.640464  4948.873847  5271.862849  ...   \n",
       "4  5840.507807  6030.352157  6037.480783  6109.355580  6000.190091  ...   \n",
       "\n",
       "        Col247       Col248       Col249       Col250       Col251  \\\n",
       "0 -1279.720481  -672.204610   -35.247405   565.001817  1139.580709   \n",
       "1 -4525.083123 -4077.498908 -3630.262875 -3176.648183 -2652.563485   \n",
       "2 -4214.790563 -3762.024055 -3303.182589 -2802.950592 -2246.516780   \n",
       "3 -4371.401183 -3937.075334 -3502.317297 -2922.179500 -2467.320667   \n",
       "4  -848.410798  -279.507713   269.777288   853.806015  1410.187144   \n",
       "\n",
       "        Col252       Col253       Col254       Col255       Col256  \n",
       "0  1623.258946  2159.189259  2729.066018  3292.437301  3770.985050  \n",
       "1 -2135.982927 -1549.968773  -970.063115  -413.973048   202.507328  \n",
       "2 -1712.153266 -1120.729328  -553.276475    43.863168   614.870963  \n",
       "3 -1904.033355 -1362.385474  -704.032900  -188.518269   466.064827  \n",
       "4  1977.999116  2621.735468  3069.781180  3624.993700  4116.325633  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   output\n",
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   output\n",
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are splitting the training set in the ratio of 70%,30% (training set,validation set)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dummies function is used here to perform one hot encoding of the y_* numpy arrays\n",
    "y_train_hot = pd.get_dummies(y_train['output'])\n",
    "y_test_hot = pd.get_dummies(y_test['output'])\n",
    "y_val_hot = pd.get_dummies(y_val['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3256</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1  2  3  4  5  6\n",
       "927   1  0  0  0  0  0\n",
       "3256  0  0  0  1  0  0\n",
       "45    1  0  0  0  0  0\n",
       "1260  0  1  0  0  0  0\n",
       "1096  0  1  0  0  0  0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_hot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data transformation steps employed here are as follows:<br>\n",
    "\n",
    "1) Fourier Transform<br>\n",
    "2) Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i in range(0,x_train.shape[0]):\\n    x_train[i][:] = np.abs(fft(x_train[i][:]))\\n    \\nfor i in range(0,x_test.shape[0]):\\n    x_test[i][:] = np.abs(fft(x_test[i][:]))\\n\\nfor i in range(0,x_val.shape[0]):\\n    x_val[i][:] = np.abs(fft(x_val[i][:]))'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we are overwritting the dataframe with the respective waves which we obtained after doing fourier \n",
    "#transformation\n",
    "'''for i in range(0,x_train.shape[0]):\n",
    "    x_train[i][:] = np.abs(fft(x_train[i][:]))\n",
    "    \n",
    "for i in range(0,x_test.shape[0]):\n",
    "    x_test[i][:] = np.abs(fft(x_test[i][:]))\n",
    "\n",
    "for i in range(0,x_val.shape[0]):\n",
    "    x_val[i][:] = np.abs(fft(x_val[i][:]))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are performing normalization\n",
    "transform = StandardScaler()\n",
    "x_train_tr = transform.fit_transform(x_train)\n",
    "x_test_tr = transform.fit_transform(x_test)\n",
    "x_val_tr = transform.fit_transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (4199, 256)\n",
      "(4199, 6)\n",
      "Validation (1800, 256)\n",
      "(1800, 6)\n",
      "Test (3599, 256)\n",
      "(3599, 6)\n"
     ]
    }
   ],
   "source": [
    "#final dimensions of the data\n",
    "print(\"Training\",x_train_tr.shape)\n",
    "print(y_train_hot.shape)\n",
    "print(\"Validation\",x_val_tr.shape)\n",
    "print(y_val_hot.shape)\n",
    "print(\"Test\",x_test_tr.shape)\n",
    "print(y_test_hot.shape)\n",
    "sampling_rate = x_train_tr.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(no_of_classes,sampling_rate):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(64, input_shape=(sampling_rate,), activation = 'relu'))\n",
    "    model.add(Dense(32, activation = 'relu'))\n",
    "    #model.add(Dropout(0.6))\n",
    "    model.add(Dense(16, activation = 'relu'))\n",
    "    #model.add(Dropout(0.6))\n",
    "    model.add(Dense(no_of_classes, activation = 'softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "66/66 [==============================] - 1s 6ms/step - loss: 1.3685 - accuracy: 0.4600 - val_loss: 0.5088 - val_accuracy: 0.8644\n",
      "Epoch 2/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3786 - accuracy: 0.8712 - val_loss: 0.2836 - val_accuracy: 0.8556\n",
      "Epoch 3/30\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2438 - accuracy: 0.8771 - val_loss: 0.2410 - val_accuracy: 0.8644\n",
      "Epoch 4/30\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 0.2132 - accuracy: 0.8931 - val_loss: 0.2572 - val_accuracy: 0.8506\n",
      "Epoch 5/30\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.1982 - accuracy: 0.8970 - val_loss: 0.2157 - val_accuracy: 0.8800\n",
      "Epoch 6/30\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.1972 - accuracy: 0.8998 - val_loss: 0.2229 - val_accuracy: 0.8850\n",
      "Epoch 7/30\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 0.2018 - accuracy: 0.8946 - val_loss: 0.2185 - val_accuracy: 0.8783\n",
      "Epoch 8/30\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.1942 - accuracy: 0.9023 - val_loss: 0.1990 - val_accuracy: 0.8928\n",
      "Epoch 9/30\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.1814 - accuracy: 0.9048 - val_loss: 0.1926 - val_accuracy: 0.8978\n",
      "Epoch 10/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1753 - accuracy: 0.9090 - val_loss: 0.1887 - val_accuracy: 0.9061\n",
      "Epoch 11/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1655 - accuracy: 0.9121 - val_loss: 0.1935 - val_accuracy: 0.9028\n",
      "Epoch 12/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1516 - accuracy: 0.9253 - val_loss: 0.2056 - val_accuracy: 0.9033\n",
      "Epoch 13/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1786 - accuracy: 0.9069 - val_loss: 0.2107 - val_accuracy: 0.8872\n",
      "Epoch 14/30\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.1931 - accuracy: 0.9111 - val_loss: 0.1868 - val_accuracy: 0.9061\n",
      "Epoch 15/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9240 - val_loss: 0.1837 - val_accuracy: 0.9111\n",
      "Epoch 16/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1530 - accuracy: 0.9210 - val_loss: 0.2030 - val_accuracy: 0.8767\n",
      "Epoch 17/30\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.1466 - accuracy: 0.9297 - val_loss: 0.1659 - val_accuracy: 0.9194\n",
      "Epoch 18/30\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.1449 - accuracy: 0.9322 - val_loss: 0.1695 - val_accuracy: 0.9161\n",
      "Epoch 19/30\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.1376 - accuracy: 0.9398 - val_loss: 0.1729 - val_accuracy: 0.9156\n",
      "Epoch 20/30\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.1513 - accuracy: 0.9221 - val_loss: 0.1907 - val_accuracy: 0.9167\n",
      "Epoch 21/30\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.1435 - accuracy: 0.9296 - val_loss: 0.1829 - val_accuracy: 0.9083\n",
      "Epoch 22/30\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.1350 - accuracy: 0.9410 - val_loss: 0.1682 - val_accuracy: 0.9189\n",
      "Epoch 23/30\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.1511 - accuracy: 0.9304 - val_loss: 0.1365 - val_accuracy: 0.9433\n",
      "Epoch 24/30\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.1356 - accuracy: 0.9389 - val_loss: 0.1451 - val_accuracy: 0.9317\n",
      "Epoch 25/30\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.1218 - accuracy: 0.9442 - val_loss: 0.2198 - val_accuracy: 0.8750\n",
      "Epoch 26/30\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.1147 - accuracy: 0.9525 - val_loss: 0.1468 - val_accuracy: 0.9311\n",
      "Epoch 27/30\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.1108 - accuracy: 0.9514 - val_loss: 0.1893 - val_accuracy: 0.9056\n",
      "Epoch 28/30\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.1116 - accuracy: 0.9474 - val_loss: 0.1851 - val_accuracy: 0.9228\n",
      "Epoch 29/30\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.1338 - accuracy: 0.9390 - val_loss: 0.1519 - val_accuracy: 0.9278\n",
      "Epoch 30/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1268 - accuracy: 0.9400 - val_loss: 0.1369 - val_accuracy: 0.9400\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_dir = \"logs2/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model = model_training(6,256)\n",
    "history = model.fit(x_train_tr, y_train_hot, batch_size=64, epochs=30, validation_data=(x_val_tr, y_val_hot), callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6010 (pid 87035), started 0:01:46 ago. (Use '!kill 87035' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-db6b67aaae6b4b8b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-db6b67aaae6b4b8b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6010;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs2/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 19,158\n",
      "Trainable params: 19,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9112090150515239"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1357 - accuracy: 0.9378\n",
      "Test accuracy is [0.13573575019836426, 0.9377604722976685]\n"
     ]
    }
   ],
   "source": [
    "pred_acc = model.evaluate(x_test_tr,y_test_hot)\n",
    "print(\"Test accuracy is {}\".format(pred_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = confusion_matrix(y_test_hot.to_numpy().argmax(axis=1), model.predict(x_test_tr).argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[546,   0,  53,   0,   0,   0],\n",
       "       [  0, 600,   0,   0,   0,   0],\n",
       "       [171,   0, 429,   0,   0,   0],\n",
       "       [  0,   0,   0, 600,   0,   0],\n",
       "       [  0,   0,   0,   0, 600,   0],\n",
       "       [  0,   0,   0,   0,   0, 600]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "to_cm = pd.DataFrame(array, index = [i for i in [\"Type-1\",\"Type-2\",\"Type-3\",\"Type-4\",\"Type-5\",\"Type-6\"]],\n",
    "                  columns = [i for i in [\"Type-1\",\"Type-2\",\"Type-3\",\"Type-4\",\"Type-5\",\"Type-6\"]])\n",
    "plt.figure(figsize = (15,10))\n",
    "sn.heatmap(to_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"model1.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
