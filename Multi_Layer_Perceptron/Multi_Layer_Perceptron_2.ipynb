{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Quality Classification using Muti Layer Perceptron (Dataset 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook focusses on developing a Multi Layer perceptron which classifies a particular power signal into its respective power quality condition. The dataset used here contains signals which belong to one of the 6 classes(power quality condition). The sampling rate of this data is 256. This means that each signal is characterized by 256 data points. Here the signals provided are in time domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.fft import fft,fftfreq\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset using pandas\n",
    "x_train = pd.read_csv(\"../Dataset2/Train/Voltage_L1_train.csv\")\n",
    "y_train = pd.read_csv(\"../Dataset2/Train/output_train.csv\")\n",
    "x_test = pd.read_csv(\"../Dataset2/Test/Voltage_L1_test.csv\")\n",
    "y_test = pd.read_csv(\"../Dataset2/Test/output_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (5999, 256)\n",
      "y_train (5999, 1)\n",
      "x_test (3599, 256)\n",
      "y_test (3599, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train\",x_train.shape)\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"x_test\",x_test.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This segment of notebook contains all the preprocessing steps which are performed on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropna() function is used to remove all those rows which contains NA values\n",
    "x_train.dropna(axis=0,inplace=True)\n",
    "y_train.dropna(axis=0,inplace=True)\n",
    "x_test.dropna(axis=0,inplace=True)\n",
    "y_test.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (5999, 256)\n",
      "y_train (5999, 1)\n",
      "x_test (3599, 256)\n",
      "y_test (3599, 1)\n"
     ]
    }
   ],
   "source": [
    "#shape of the data frame after dropping the rows containing NA values\n",
    "print(\"x_train\",x_train.shape)\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"x_test\",x_test.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are constructing the array which will finally contain the column names\n",
    "header =[]\n",
    "for i in range(1,x_train.shape[1]+1):\n",
    "    header.append(\"Col\"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the column name array to the respectinve dataframes\n",
    "x_train.columns = header\n",
    "x_test.columns = header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the column name array to the respectinve dataframes\n",
    "header = [\"output\"]\n",
    "y_train.columns = header\n",
    "y_test.columns = header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "      <th>...</th>\n",
       "      <th>Col247</th>\n",
       "      <th>Col248</th>\n",
       "      <th>Col249</th>\n",
       "      <th>Col250</th>\n",
       "      <th>Col251</th>\n",
       "      <th>Col252</th>\n",
       "      <th>Col253</th>\n",
       "      <th>Col254</th>\n",
       "      <th>Col255</th>\n",
       "      <th>Col256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>573.652486</td>\n",
       "      <td>1003.343736</td>\n",
       "      <td>1588.404525</td>\n",
       "      <td>2317.576741</td>\n",
       "      <td>2804.364311</td>\n",
       "      <td>3225.322510</td>\n",
       "      <td>3662.821690</td>\n",
       "      <td>4174.627969</td>\n",
       "      <td>4656.244143</td>\n",
       "      <td>4939.070130</td>\n",
       "      <td>...</td>\n",
       "      <td>-4650.282434</td>\n",
       "      <td>-4228.581226</td>\n",
       "      <td>-3865.609932</td>\n",
       "      <td>-3395.654756</td>\n",
       "      <td>-2933.680470</td>\n",
       "      <td>-2322.450904</td>\n",
       "      <td>-1841.562453</td>\n",
       "      <td>-1282.042025</td>\n",
       "      <td>-601.968217</td>\n",
       "      <td>-156.848367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4757.365183</td>\n",
       "      <td>5264.598912</td>\n",
       "      <td>5428.642486</td>\n",
       "      <td>5650.413073</td>\n",
       "      <td>5939.710012</td>\n",
       "      <td>5911.948067</td>\n",
       "      <td>6147.642171</td>\n",
       "      <td>6076.921501</td>\n",
       "      <td>5958.797444</td>\n",
       "      <td>6053.817701</td>\n",
       "      <td>...</td>\n",
       "      <td>-280.360872</td>\n",
       "      <td>323.325836</td>\n",
       "      <td>861.103019</td>\n",
       "      <td>1415.929276</td>\n",
       "      <td>2007.692919</td>\n",
       "      <td>2561.130303</td>\n",
       "      <td>2960.282598</td>\n",
       "      <td>3619.932691</td>\n",
       "      <td>4008.288701</td>\n",
       "      <td>4422.229911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4242.144824</td>\n",
       "      <td>4644.679402</td>\n",
       "      <td>5013.356532</td>\n",
       "      <td>5229.417051</td>\n",
       "      <td>5534.898007</td>\n",
       "      <td>5797.190678</td>\n",
       "      <td>5930.658682</td>\n",
       "      <td>5960.014599</td>\n",
       "      <td>6055.336310</td>\n",
       "      <td>6103.707793</td>\n",
       "      <td>...</td>\n",
       "      <td>-1256.270585</td>\n",
       "      <td>-616.527428</td>\n",
       "      <td>-67.068193</td>\n",
       "      <td>549.016676</td>\n",
       "      <td>1099.652199</td>\n",
       "      <td>1697.572166</td>\n",
       "      <td>2239.961604</td>\n",
       "      <td>2776.876479</td>\n",
       "      <td>3248.638662</td>\n",
       "      <td>3807.665149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2077.819247</td>\n",
       "      <td>2561.679246</td>\n",
       "      <td>3085.653813</td>\n",
       "      <td>3545.905160</td>\n",
       "      <td>4023.421592</td>\n",
       "      <td>4496.705157</td>\n",
       "      <td>4809.079868</td>\n",
       "      <td>5186.298840</td>\n",
       "      <td>5453.627533</td>\n",
       "      <td>5737.354699</td>\n",
       "      <td>...</td>\n",
       "      <td>-3557.345152</td>\n",
       "      <td>-3017.951179</td>\n",
       "      <td>-2596.647329</td>\n",
       "      <td>-1996.266675</td>\n",
       "      <td>-1467.203661</td>\n",
       "      <td>-885.101101</td>\n",
       "      <td>-329.685256</td>\n",
       "      <td>304.222722</td>\n",
       "      <td>935.528504</td>\n",
       "      <td>1460.127297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3599.645319</td>\n",
       "      <td>4099.944762</td>\n",
       "      <td>4499.282469</td>\n",
       "      <td>4897.875855</td>\n",
       "      <td>5120.077118</td>\n",
       "      <td>5402.227743</td>\n",
       "      <td>5694.801362</td>\n",
       "      <td>5928.683099</td>\n",
       "      <td>5981.616502</td>\n",
       "      <td>6052.006904</td>\n",
       "      <td>...</td>\n",
       "      <td>-2020.240712</td>\n",
       "      <td>-1388.704968</td>\n",
       "      <td>-849.731284</td>\n",
       "      <td>-232.632694</td>\n",
       "      <td>341.406093</td>\n",
       "      <td>854.579135</td>\n",
       "      <td>1528.023058</td>\n",
       "      <td>2002.557438</td>\n",
       "      <td>2576.468343</td>\n",
       "      <td>3036.303600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Col1         Col2         Col3         Col4         Col5  \\\n",
       "0   573.652486  1003.343736  1588.404525  2317.576741  2804.364311   \n",
       "1  4757.365183  5264.598912  5428.642486  5650.413073  5939.710012   \n",
       "2  4242.144824  4644.679402  5013.356532  5229.417051  5534.898007   \n",
       "3  2077.819247  2561.679246  3085.653813  3545.905160  4023.421592   \n",
       "4  3599.645319  4099.944762  4499.282469  4897.875855  5120.077118   \n",
       "\n",
       "          Col6         Col7         Col8         Col9        Col10  ...  \\\n",
       "0  3225.322510  3662.821690  4174.627969  4656.244143  4939.070130  ...   \n",
       "1  5911.948067  6147.642171  6076.921501  5958.797444  6053.817701  ...   \n",
       "2  5797.190678  5930.658682  5960.014599  6055.336310  6103.707793  ...   \n",
       "3  4496.705157  4809.079868  5186.298840  5453.627533  5737.354699  ...   \n",
       "4  5402.227743  5694.801362  5928.683099  5981.616502  6052.006904  ...   \n",
       "\n",
       "        Col247       Col248       Col249       Col250       Col251  \\\n",
       "0 -4650.282434 -4228.581226 -3865.609932 -3395.654756 -2933.680470   \n",
       "1  -280.360872   323.325836   861.103019  1415.929276  2007.692919   \n",
       "2 -1256.270585  -616.527428   -67.068193   549.016676  1099.652199   \n",
       "3 -3557.345152 -3017.951179 -2596.647329 -1996.266675 -1467.203661   \n",
       "4 -2020.240712 -1388.704968  -849.731284  -232.632694   341.406093   \n",
       "\n",
       "        Col252       Col253       Col254       Col255       Col256  \n",
       "0 -2322.450904 -1841.562453 -1282.042025  -601.968217  -156.848367  \n",
       "1  2561.130303  2960.282598  3619.932691  4008.288701  4422.229911  \n",
       "2  1697.572166  2239.961604  2776.876479  3248.638662  3807.665149  \n",
       "3  -885.101101  -329.685256   304.222722   935.528504  1460.127297  \n",
       "4   854.579135  1528.023058  2002.557438  2576.468343  3036.303600  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "      <th>...</th>\n",
       "      <th>Col247</th>\n",
       "      <th>Col248</th>\n",
       "      <th>Col249</th>\n",
       "      <th>Col250</th>\n",
       "      <th>Col251</th>\n",
       "      <th>Col252</th>\n",
       "      <th>Col253</th>\n",
       "      <th>Col254</th>\n",
       "      <th>Col255</th>\n",
       "      <th>Col256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4216.164293</td>\n",
       "      <td>4550.919227</td>\n",
       "      <td>4885.253969</td>\n",
       "      <td>5265.577080</td>\n",
       "      <td>5634.058181</td>\n",
       "      <td>5690.878844</td>\n",
       "      <td>5984.805444</td>\n",
       "      <td>6083.124480</td>\n",
       "      <td>6024.018340</td>\n",
       "      <td>6144.339029</td>\n",
       "      <td>...</td>\n",
       "      <td>-1279.720481</td>\n",
       "      <td>-672.204610</td>\n",
       "      <td>-35.247405</td>\n",
       "      <td>565.001817</td>\n",
       "      <td>1139.580709</td>\n",
       "      <td>1623.258946</td>\n",
       "      <td>2159.189259</td>\n",
       "      <td>2729.066018</td>\n",
       "      <td>3292.437301</td>\n",
       "      <td>3770.985050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>795.638794</td>\n",
       "      <td>1340.736614</td>\n",
       "      <td>1928.805243</td>\n",
       "      <td>2465.916079</td>\n",
       "      <td>3009.942949</td>\n",
       "      <td>3475.153730</td>\n",
       "      <td>3938.568022</td>\n",
       "      <td>4372.781654</td>\n",
       "      <td>4765.603003</td>\n",
       "      <td>5090.817748</td>\n",
       "      <td>...</td>\n",
       "      <td>-4525.083123</td>\n",
       "      <td>-4077.498908</td>\n",
       "      <td>-3630.262875</td>\n",
       "      <td>-3176.648183</td>\n",
       "      <td>-2652.563485</td>\n",
       "      <td>-2135.982927</td>\n",
       "      <td>-1549.968773</td>\n",
       "      <td>-970.063115</td>\n",
       "      <td>-413.973048</td>\n",
       "      <td>202.507328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1220.943267</td>\n",
       "      <td>1770.550513</td>\n",
       "      <td>2318.816674</td>\n",
       "      <td>2850.186275</td>\n",
       "      <td>3357.786987</td>\n",
       "      <td>3848.017230</td>\n",
       "      <td>4274.339651</td>\n",
       "      <td>4669.175893</td>\n",
       "      <td>5027.840955</td>\n",
       "      <td>5329.856655</td>\n",
       "      <td>...</td>\n",
       "      <td>-4214.790563</td>\n",
       "      <td>-3762.024055</td>\n",
       "      <td>-3303.182589</td>\n",
       "      <td>-2802.950592</td>\n",
       "      <td>-2246.516780</td>\n",
       "      <td>-1712.153266</td>\n",
       "      <td>-1120.729328</td>\n",
       "      <td>-553.276475</td>\n",
       "      <td>43.863168</td>\n",
       "      <td>614.870963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1013.772210</td>\n",
       "      <td>1621.783618</td>\n",
       "      <td>2178.146635</td>\n",
       "      <td>2733.460484</td>\n",
       "      <td>3178.151416</td>\n",
       "      <td>3692.797702</td>\n",
       "      <td>4177.895304</td>\n",
       "      <td>4539.640464</td>\n",
       "      <td>4948.873847</td>\n",
       "      <td>5271.862849</td>\n",
       "      <td>...</td>\n",
       "      <td>-4371.401183</td>\n",
       "      <td>-3937.075334</td>\n",
       "      <td>-3502.317297</td>\n",
       "      <td>-2922.179500</td>\n",
       "      <td>-2467.320667</td>\n",
       "      <td>-1904.033355</td>\n",
       "      <td>-1362.385474</td>\n",
       "      <td>-704.032900</td>\n",
       "      <td>-188.518269</td>\n",
       "      <td>466.064827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4490.355896</td>\n",
       "      <td>4862.601717</td>\n",
       "      <td>5235.681699</td>\n",
       "      <td>5401.432840</td>\n",
       "      <td>5741.255908</td>\n",
       "      <td>5840.507807</td>\n",
       "      <td>6030.352157</td>\n",
       "      <td>6037.480783</td>\n",
       "      <td>6109.355580</td>\n",
       "      <td>6000.190091</td>\n",
       "      <td>...</td>\n",
       "      <td>-848.410798</td>\n",
       "      <td>-279.507713</td>\n",
       "      <td>269.777288</td>\n",
       "      <td>853.806015</td>\n",
       "      <td>1410.187144</td>\n",
       "      <td>1977.999116</td>\n",
       "      <td>2621.735468</td>\n",
       "      <td>3069.781180</td>\n",
       "      <td>3624.993700</td>\n",
       "      <td>4116.325633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Col1         Col2         Col3         Col4         Col5  \\\n",
       "0  4216.164293  4550.919227  4885.253969  5265.577080  5634.058181   \n",
       "1   795.638794  1340.736614  1928.805243  2465.916079  3009.942949   \n",
       "2  1220.943267  1770.550513  2318.816674  2850.186275  3357.786987   \n",
       "3  1013.772210  1621.783618  2178.146635  2733.460484  3178.151416   \n",
       "4  4490.355896  4862.601717  5235.681699  5401.432840  5741.255908   \n",
       "\n",
       "          Col6         Col7         Col8         Col9        Col10  ...  \\\n",
       "0  5690.878844  5984.805444  6083.124480  6024.018340  6144.339029  ...   \n",
       "1  3475.153730  3938.568022  4372.781654  4765.603003  5090.817748  ...   \n",
       "2  3848.017230  4274.339651  4669.175893  5027.840955  5329.856655  ...   \n",
       "3  3692.797702  4177.895304  4539.640464  4948.873847  5271.862849  ...   \n",
       "4  5840.507807  6030.352157  6037.480783  6109.355580  6000.190091  ...   \n",
       "\n",
       "        Col247       Col248       Col249       Col250       Col251  \\\n",
       "0 -1279.720481  -672.204610   -35.247405   565.001817  1139.580709   \n",
       "1 -4525.083123 -4077.498908 -3630.262875 -3176.648183 -2652.563485   \n",
       "2 -4214.790563 -3762.024055 -3303.182589 -2802.950592 -2246.516780   \n",
       "3 -4371.401183 -3937.075334 -3502.317297 -2922.179500 -2467.320667   \n",
       "4  -848.410798  -279.507713   269.777288   853.806015  1410.187144   \n",
       "\n",
       "        Col252       Col253       Col254       Col255       Col256  \n",
       "0  1623.258946  2159.189259  2729.066018  3292.437301  3770.985050  \n",
       "1 -2135.982927 -1549.968773  -970.063115  -413.973048   202.507328  \n",
       "2 -1712.153266 -1120.729328  -553.276475    43.863168   614.870963  \n",
       "3 -1904.033355 -1362.385474  -704.032900  -188.518269   466.064827  \n",
       "4  1977.999116  2621.735468  3069.781180  3624.993700  4116.325633  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   output\n",
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   output\n",
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are splitting the training set in the ratio of 70%,30% (training set,validation set)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dummies function is used here to perform one hot encoding of the y_* numpy arrays\n",
    "y_train_hot = pd.get_dummies(y_train['output'])\n",
    "y_test_hot = pd.get_dummies(y_test['output'])\n",
    "y_val_hot = pd.get_dummies(y_val['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3256</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1  2  3  4  5  6\n",
       "927   1  0  0  0  0  0\n",
       "3256  0  0  0  1  0  0\n",
       "45    1  0  0  0  0  0\n",
       "1260  0  1  0  0  0  0\n",
       "1096  0  1  0  0  0  0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_hot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data transformation steps employed here are as follows:<br>\n",
    "\n",
    "1) Fourier Transform<br>\n",
    "2) Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are overwritting the dataframe with the respective waves which we obtained after doing fourier \n",
    "#transformation\n",
    "for i in range(0,x_train.shape[0]):\n",
    "    x_train[i][:] = np.abs(fft(x_train[i][:]))\n",
    "    \n",
    "for i in range(0,x_test.shape[0]):\n",
    "    x_test[i][:] = np.abs(fft(x_test[i][:]))\n",
    "\n",
    "for i in range(0,x_val.shape[0]):\n",
    "    x_val[i][:] = np.abs(fft(x_val[i][:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are performing normalization\n",
    "transform = StandardScaler()\n",
    "x_train_tr = transform.fit_transform(x_train)\n",
    "x_test_tr = transform.fit_transform(x_test)\n",
    "x_val_tr = transform.fit_transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (4199, 256)\n",
      "(4199, 6)\n",
      "Validation (1800, 256)\n",
      "(1800, 6)\n",
      "Test (3599, 256)\n",
      "(3599, 6)\n"
     ]
    }
   ],
   "source": [
    "#final dimensions of the data\n",
    "print(\"Training\",x_train_tr.shape)\n",
    "print(y_train_hot.shape)\n",
    "print(\"Validation\",x_val_tr.shape)\n",
    "print(y_val_hot.shape)\n",
    "print(\"Test\",x_test_tr.shape)\n",
    "print(y_test_hot.shape)\n",
    "sampling_rate = x_train_tr.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(no_of_classes,sampling_rate):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(64, input_shape=(sampling_rate,), activation = 'relu'))\n",
    "    model.add(Dense(32, activation = 'relu'))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(16, activation = 'relu'))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(no_of_classes, activation = 'softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.7322 - accuracy: 0.2591 - val_loss: 1.2120 - val_accuracy: 0.9228\n",
      "Epoch 2/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.3664 - accuracy: 0.4196 - val_loss: 0.7488 - val_accuracy: 0.9911\n",
      "Epoch 3/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.1143 - accuracy: 0.5298 - val_loss: 0.4519 - val_accuracy: 0.9967\n",
      "Epoch 4/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8984 - accuracy: 0.6299 - val_loss: 0.2284 - val_accuracy: 0.9989\n",
      "Epoch 5/30\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.7992 - accuracy: 0.6511 - val_loss: 0.1295 - val_accuracy: 0.9983\n",
      "Epoch 6/30\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.7283 - accuracy: 0.6893 - val_loss: 0.0788 - val_accuracy: 0.9983\n",
      "Epoch 7/30\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.6706 - accuracy: 0.7088 - val_loss: 0.0555 - val_accuracy: 0.9989\n",
      "Epoch 8/30\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.5975 - accuracy: 0.7295 - val_loss: 0.0281 - val_accuracy: 0.9989\n",
      "Epoch 9/30\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.5675 - accuracy: 0.7496 - val_loss: 0.0188 - val_accuracy: 0.9989\n",
      "Epoch 10/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7725 - val_loss: 0.0119 - val_accuracy: 0.9989\n",
      "Epoch 11/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7765 - val_loss: 0.0118 - val_accuracy: 0.9989\n",
      "Epoch 12/30\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.4892 - accuracy: 0.7869 - val_loss: 0.0075 - val_accuracy: 0.9994\n",
      "Epoch 13/30\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 0.4618 - accuracy: 0.7915 - val_loss: 0.0056 - val_accuracy: 0.9994\n",
      "Epoch 14/30\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 0.4578 - accuracy: 0.7972 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
      "Epoch 15/30\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 0.4676 - accuracy: 0.7929 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.4086 - accuracy: 0.8200 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8309 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8279 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8198 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 0.4041 - accuracy: 0.8241 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 0.3941 - accuracy: 0.8285 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.3724 - accuracy: 0.8384 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8353 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3747 - accuracy: 0.8318 - val_loss: 8.7556e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3467 - accuracy: 0.8513 - val_loss: 7.2703e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.3526 - accuracy: 0.8560 - val_loss: 8.1494e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.3723 - accuracy: 0.8317 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.3393 - accuracy: 0.8529 - val_loss: 7.3661e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8500 - val_loss: 7.1259e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3011 - accuracy: 0.8656 - val_loss: 9.9942e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = model_training(6,256)\n",
    "history = model.fit(x_train_tr, y_train_hot, batch_size=64, epochs=30, validation_data=(x_val_tr, y_val_hot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 19,158\n",
      "Trainable params: 19,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9903\n",
      "Test accuracy is [0.036277420818805695, 0.9902750849723816]\n"
     ]
    }
   ],
   "source": [
    "pred_acc = model.evaluate(x_test_tr,y_test_hot)\n",
    "print(\"Test accuracy is {}\".format(pred_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = confusion_matrix(y_test_hot.to_numpy().argmax(axis=1), model.predict(x_test_tr).argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[567,   0,  32,   0,   0,   0],\n",
       "       [  0, 600,   0,   0,   0,   0],\n",
       "       [  3,   0, 597,   0,   0,   0],\n",
       "       [  0,   0,   0, 600,   0,   0],\n",
       "       [  0,   0,   0,   0, 600,   0],\n",
       "       [  0,   0,   0,   0,   0, 600]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "to_cm = pd.DataFrame(array, index = [i for i in [\"Type-1\",\"Type-2\",\"Type-3\",\"Type-4\",\"Type-5\",\"Type-6\"]],\n",
    "                  columns = [i for i in [\"Type-1\",\"Type-2\",\"Type-3\",\"Type-4\",\"Type-5\",\"Type-6\"]])\n",
    "plt.figure(figsize = (15,10))\n",
    "sn.heatmap(to_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
