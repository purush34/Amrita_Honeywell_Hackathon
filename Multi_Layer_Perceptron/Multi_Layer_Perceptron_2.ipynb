{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Quality Classification using Muti Layer Perceptron (Dataset 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook focusses on developing a Multi Layer perceptron which classifies a particular power signal into its respective power quality condition. The dataset used here contains signals which belong to one of the 6 classes(power quality condition). The sampling rate of this data is 256. This means that each signal is characterized by 256 data points. Here the signals provided are in time domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.fft import fft,fftfreq\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset using pandas\n",
    "x_train = pd.read_csv(\"../Dataset2/Train/Voltage_L1_train.csv\")\n",
    "y_train = pd.read_csv(\"../Dataset2/Train/output_train.csv\")\n",
    "x_test = pd.read_csv(\"../Dataset2/Test/Voltage_L1_test.csv\")\n",
    "y_test = pd.read_csv(\"../Dataset2/Test/output_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (5999, 256)\n",
      "y_train (5999, 1)\n",
      "x_test (3599, 256)\n",
      "y_test (3599, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train\",x_train.shape)\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"x_test\",x_test.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This segment of notebook contains all the preprocessing steps which are performed on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropna() function is used to remove all those rows which contains NA values\n",
    "x_train.dropna(axis=0,inplace=True)\n",
    "y_train.dropna(axis=0,inplace=True)\n",
    "x_test.dropna(axis=0,inplace=True)\n",
    "y_test.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (5999, 256)\n",
      "y_train (5999, 1)\n",
      "x_test (3599, 256)\n",
      "y_test (3599, 1)\n"
     ]
    }
   ],
   "source": [
    "#shape of the data frame after dropping the rows containing NA values\n",
    "print(\"x_train\",x_train.shape)\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"x_test\",x_test.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are constructing the array which will finally contain the column names\n",
    "header =[]\n",
    "for i in range(1,x_train.shape[1]+1):\n",
    "    header.append(\"Col\"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the column name array to the respectinve dataframes\n",
    "x_train.columns = header\n",
    "x_test.columns = header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the column name array to the respectinve dataframes\n",
    "header = [\"output\"]\n",
    "y_train.columns = header\n",
    "y_test.columns = header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "      <th>...</th>\n",
       "      <th>Col247</th>\n",
       "      <th>Col248</th>\n",
       "      <th>Col249</th>\n",
       "      <th>Col250</th>\n",
       "      <th>Col251</th>\n",
       "      <th>Col252</th>\n",
       "      <th>Col253</th>\n",
       "      <th>Col254</th>\n",
       "      <th>Col255</th>\n",
       "      <th>Col256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>573.652486</td>\n",
       "      <td>1003.343736</td>\n",
       "      <td>1588.404525</td>\n",
       "      <td>2317.576741</td>\n",
       "      <td>2804.364311</td>\n",
       "      <td>3225.322510</td>\n",
       "      <td>3662.821690</td>\n",
       "      <td>4174.627969</td>\n",
       "      <td>4656.244143</td>\n",
       "      <td>4939.070130</td>\n",
       "      <td>...</td>\n",
       "      <td>-4650.282434</td>\n",
       "      <td>-4228.581226</td>\n",
       "      <td>-3865.609932</td>\n",
       "      <td>-3395.654756</td>\n",
       "      <td>-2933.680470</td>\n",
       "      <td>-2322.450904</td>\n",
       "      <td>-1841.562453</td>\n",
       "      <td>-1282.042025</td>\n",
       "      <td>-601.968217</td>\n",
       "      <td>-156.848367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4757.365183</td>\n",
       "      <td>5264.598912</td>\n",
       "      <td>5428.642486</td>\n",
       "      <td>5650.413073</td>\n",
       "      <td>5939.710012</td>\n",
       "      <td>5911.948067</td>\n",
       "      <td>6147.642171</td>\n",
       "      <td>6076.921501</td>\n",
       "      <td>5958.797444</td>\n",
       "      <td>6053.817701</td>\n",
       "      <td>...</td>\n",
       "      <td>-280.360872</td>\n",
       "      <td>323.325836</td>\n",
       "      <td>861.103019</td>\n",
       "      <td>1415.929276</td>\n",
       "      <td>2007.692919</td>\n",
       "      <td>2561.130303</td>\n",
       "      <td>2960.282598</td>\n",
       "      <td>3619.932691</td>\n",
       "      <td>4008.288701</td>\n",
       "      <td>4422.229911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4242.144824</td>\n",
       "      <td>4644.679402</td>\n",
       "      <td>5013.356532</td>\n",
       "      <td>5229.417051</td>\n",
       "      <td>5534.898007</td>\n",
       "      <td>5797.190678</td>\n",
       "      <td>5930.658682</td>\n",
       "      <td>5960.014599</td>\n",
       "      <td>6055.336310</td>\n",
       "      <td>6103.707793</td>\n",
       "      <td>...</td>\n",
       "      <td>-1256.270585</td>\n",
       "      <td>-616.527428</td>\n",
       "      <td>-67.068193</td>\n",
       "      <td>549.016676</td>\n",
       "      <td>1099.652199</td>\n",
       "      <td>1697.572166</td>\n",
       "      <td>2239.961604</td>\n",
       "      <td>2776.876479</td>\n",
       "      <td>3248.638662</td>\n",
       "      <td>3807.665149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2077.819247</td>\n",
       "      <td>2561.679246</td>\n",
       "      <td>3085.653813</td>\n",
       "      <td>3545.905160</td>\n",
       "      <td>4023.421592</td>\n",
       "      <td>4496.705157</td>\n",
       "      <td>4809.079868</td>\n",
       "      <td>5186.298840</td>\n",
       "      <td>5453.627533</td>\n",
       "      <td>5737.354699</td>\n",
       "      <td>...</td>\n",
       "      <td>-3557.345152</td>\n",
       "      <td>-3017.951179</td>\n",
       "      <td>-2596.647329</td>\n",
       "      <td>-1996.266675</td>\n",
       "      <td>-1467.203661</td>\n",
       "      <td>-885.101101</td>\n",
       "      <td>-329.685256</td>\n",
       "      <td>304.222722</td>\n",
       "      <td>935.528504</td>\n",
       "      <td>1460.127297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3599.645319</td>\n",
       "      <td>4099.944762</td>\n",
       "      <td>4499.282469</td>\n",
       "      <td>4897.875855</td>\n",
       "      <td>5120.077118</td>\n",
       "      <td>5402.227743</td>\n",
       "      <td>5694.801362</td>\n",
       "      <td>5928.683099</td>\n",
       "      <td>5981.616502</td>\n",
       "      <td>6052.006904</td>\n",
       "      <td>...</td>\n",
       "      <td>-2020.240712</td>\n",
       "      <td>-1388.704968</td>\n",
       "      <td>-849.731284</td>\n",
       "      <td>-232.632694</td>\n",
       "      <td>341.406093</td>\n",
       "      <td>854.579135</td>\n",
       "      <td>1528.023058</td>\n",
       "      <td>2002.557438</td>\n",
       "      <td>2576.468343</td>\n",
       "      <td>3036.303600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Col1         Col2         Col3         Col4         Col5  \\\n",
       "0   573.652486  1003.343736  1588.404525  2317.576741  2804.364311   \n",
       "1  4757.365183  5264.598912  5428.642486  5650.413073  5939.710012   \n",
       "2  4242.144824  4644.679402  5013.356532  5229.417051  5534.898007   \n",
       "3  2077.819247  2561.679246  3085.653813  3545.905160  4023.421592   \n",
       "4  3599.645319  4099.944762  4499.282469  4897.875855  5120.077118   \n",
       "\n",
       "          Col6         Col7         Col8         Col9        Col10  ...  \\\n",
       "0  3225.322510  3662.821690  4174.627969  4656.244143  4939.070130  ...   \n",
       "1  5911.948067  6147.642171  6076.921501  5958.797444  6053.817701  ...   \n",
       "2  5797.190678  5930.658682  5960.014599  6055.336310  6103.707793  ...   \n",
       "3  4496.705157  4809.079868  5186.298840  5453.627533  5737.354699  ...   \n",
       "4  5402.227743  5694.801362  5928.683099  5981.616502  6052.006904  ...   \n",
       "\n",
       "        Col247       Col248       Col249       Col250       Col251  \\\n",
       "0 -4650.282434 -4228.581226 -3865.609932 -3395.654756 -2933.680470   \n",
       "1  -280.360872   323.325836   861.103019  1415.929276  2007.692919   \n",
       "2 -1256.270585  -616.527428   -67.068193   549.016676  1099.652199   \n",
       "3 -3557.345152 -3017.951179 -2596.647329 -1996.266675 -1467.203661   \n",
       "4 -2020.240712 -1388.704968  -849.731284  -232.632694   341.406093   \n",
       "\n",
       "        Col252       Col253       Col254       Col255       Col256  \n",
       "0 -2322.450904 -1841.562453 -1282.042025  -601.968217  -156.848367  \n",
       "1  2561.130303  2960.282598  3619.932691  4008.288701  4422.229911  \n",
       "2  1697.572166  2239.961604  2776.876479  3248.638662  3807.665149  \n",
       "3  -885.101101  -329.685256   304.222722   935.528504  1460.127297  \n",
       "4   854.579135  1528.023058  2002.557438  2576.468343  3036.303600  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "      <th>...</th>\n",
       "      <th>Col247</th>\n",
       "      <th>Col248</th>\n",
       "      <th>Col249</th>\n",
       "      <th>Col250</th>\n",
       "      <th>Col251</th>\n",
       "      <th>Col252</th>\n",
       "      <th>Col253</th>\n",
       "      <th>Col254</th>\n",
       "      <th>Col255</th>\n",
       "      <th>Col256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4216.164293</td>\n",
       "      <td>4550.919227</td>\n",
       "      <td>4885.253969</td>\n",
       "      <td>5265.577080</td>\n",
       "      <td>5634.058181</td>\n",
       "      <td>5690.878844</td>\n",
       "      <td>5984.805444</td>\n",
       "      <td>6083.124480</td>\n",
       "      <td>6024.018340</td>\n",
       "      <td>6144.339029</td>\n",
       "      <td>...</td>\n",
       "      <td>-1279.720481</td>\n",
       "      <td>-672.204610</td>\n",
       "      <td>-35.247405</td>\n",
       "      <td>565.001817</td>\n",
       "      <td>1139.580709</td>\n",
       "      <td>1623.258946</td>\n",
       "      <td>2159.189259</td>\n",
       "      <td>2729.066018</td>\n",
       "      <td>3292.437301</td>\n",
       "      <td>3770.985050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>795.638794</td>\n",
       "      <td>1340.736614</td>\n",
       "      <td>1928.805243</td>\n",
       "      <td>2465.916079</td>\n",
       "      <td>3009.942949</td>\n",
       "      <td>3475.153730</td>\n",
       "      <td>3938.568022</td>\n",
       "      <td>4372.781654</td>\n",
       "      <td>4765.603003</td>\n",
       "      <td>5090.817748</td>\n",
       "      <td>...</td>\n",
       "      <td>-4525.083123</td>\n",
       "      <td>-4077.498908</td>\n",
       "      <td>-3630.262875</td>\n",
       "      <td>-3176.648183</td>\n",
       "      <td>-2652.563485</td>\n",
       "      <td>-2135.982927</td>\n",
       "      <td>-1549.968773</td>\n",
       "      <td>-970.063115</td>\n",
       "      <td>-413.973048</td>\n",
       "      <td>202.507328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1220.943267</td>\n",
       "      <td>1770.550513</td>\n",
       "      <td>2318.816674</td>\n",
       "      <td>2850.186275</td>\n",
       "      <td>3357.786987</td>\n",
       "      <td>3848.017230</td>\n",
       "      <td>4274.339651</td>\n",
       "      <td>4669.175893</td>\n",
       "      <td>5027.840955</td>\n",
       "      <td>5329.856655</td>\n",
       "      <td>...</td>\n",
       "      <td>-4214.790563</td>\n",
       "      <td>-3762.024055</td>\n",
       "      <td>-3303.182589</td>\n",
       "      <td>-2802.950592</td>\n",
       "      <td>-2246.516780</td>\n",
       "      <td>-1712.153266</td>\n",
       "      <td>-1120.729328</td>\n",
       "      <td>-553.276475</td>\n",
       "      <td>43.863168</td>\n",
       "      <td>614.870963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1013.772210</td>\n",
       "      <td>1621.783618</td>\n",
       "      <td>2178.146635</td>\n",
       "      <td>2733.460484</td>\n",
       "      <td>3178.151416</td>\n",
       "      <td>3692.797702</td>\n",
       "      <td>4177.895304</td>\n",
       "      <td>4539.640464</td>\n",
       "      <td>4948.873847</td>\n",
       "      <td>5271.862849</td>\n",
       "      <td>...</td>\n",
       "      <td>-4371.401183</td>\n",
       "      <td>-3937.075334</td>\n",
       "      <td>-3502.317297</td>\n",
       "      <td>-2922.179500</td>\n",
       "      <td>-2467.320667</td>\n",
       "      <td>-1904.033355</td>\n",
       "      <td>-1362.385474</td>\n",
       "      <td>-704.032900</td>\n",
       "      <td>-188.518269</td>\n",
       "      <td>466.064827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4490.355896</td>\n",
       "      <td>4862.601717</td>\n",
       "      <td>5235.681699</td>\n",
       "      <td>5401.432840</td>\n",
       "      <td>5741.255908</td>\n",
       "      <td>5840.507807</td>\n",
       "      <td>6030.352157</td>\n",
       "      <td>6037.480783</td>\n",
       "      <td>6109.355580</td>\n",
       "      <td>6000.190091</td>\n",
       "      <td>...</td>\n",
       "      <td>-848.410798</td>\n",
       "      <td>-279.507713</td>\n",
       "      <td>269.777288</td>\n",
       "      <td>853.806015</td>\n",
       "      <td>1410.187144</td>\n",
       "      <td>1977.999116</td>\n",
       "      <td>2621.735468</td>\n",
       "      <td>3069.781180</td>\n",
       "      <td>3624.993700</td>\n",
       "      <td>4116.325633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Col1         Col2         Col3         Col4         Col5  \\\n",
       "0  4216.164293  4550.919227  4885.253969  5265.577080  5634.058181   \n",
       "1   795.638794  1340.736614  1928.805243  2465.916079  3009.942949   \n",
       "2  1220.943267  1770.550513  2318.816674  2850.186275  3357.786987   \n",
       "3  1013.772210  1621.783618  2178.146635  2733.460484  3178.151416   \n",
       "4  4490.355896  4862.601717  5235.681699  5401.432840  5741.255908   \n",
       "\n",
       "          Col6         Col7         Col8         Col9        Col10  ...  \\\n",
       "0  5690.878844  5984.805444  6083.124480  6024.018340  6144.339029  ...   \n",
       "1  3475.153730  3938.568022  4372.781654  4765.603003  5090.817748  ...   \n",
       "2  3848.017230  4274.339651  4669.175893  5027.840955  5329.856655  ...   \n",
       "3  3692.797702  4177.895304  4539.640464  4948.873847  5271.862849  ...   \n",
       "4  5840.507807  6030.352157  6037.480783  6109.355580  6000.190091  ...   \n",
       "\n",
       "        Col247       Col248       Col249       Col250       Col251  \\\n",
       "0 -1279.720481  -672.204610   -35.247405   565.001817  1139.580709   \n",
       "1 -4525.083123 -4077.498908 -3630.262875 -3176.648183 -2652.563485   \n",
       "2 -4214.790563 -3762.024055 -3303.182589 -2802.950592 -2246.516780   \n",
       "3 -4371.401183 -3937.075334 -3502.317297 -2922.179500 -2467.320667   \n",
       "4  -848.410798  -279.507713   269.777288   853.806015  1410.187144   \n",
       "\n",
       "        Col252       Col253       Col254       Col255       Col256  \n",
       "0  1623.258946  2159.189259  2729.066018  3292.437301  3770.985050  \n",
       "1 -2135.982927 -1549.968773  -970.063115  -413.973048   202.507328  \n",
       "2 -1712.153266 -1120.729328  -553.276475    43.863168   614.870963  \n",
       "3 -1904.033355 -1362.385474  -704.032900  -188.518269   466.064827  \n",
       "4  1977.999116  2621.735468  3069.781180  3624.993700  4116.325633  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   output\n",
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   output\n",
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are splitting the training set in the ratio of 70%,30% (training set,validation set)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dummies function is used here to perform one hot encoding of the y_* numpy arrays\n",
    "y_train_hot = pd.get_dummies(y_train['output'])\n",
    "y_test_hot = pd.get_dummies(y_test['output'])\n",
    "y_val_hot = pd.get_dummies(y_val['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3256</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1  2  3  4  5  6\n",
       "927   1  0  0  0  0  0\n",
       "3256  0  0  0  1  0  0\n",
       "45    1  0  0  0  0  0\n",
       "1260  0  1  0  0  0  0\n",
       "1096  0  1  0  0  0  0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_hot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data transformation steps employed here are as follows:<br>\n",
    "\n",
    "1) Fourier Transform<br>\n",
    "2) Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are overwritting the dataframe with the respective waves which we obtained after doing fourier \n",
    "#transformation\n",
    "for i in range(0,x_train.shape[0]):\n",
    "    x_train[i][:] = np.abs(fft(x_train[i][:]))\n",
    "    \n",
    "for i in range(0,x_test.shape[0]):\n",
    "    x_test[i][:] = np.abs(fft(x_test[i][:]))\n",
    "\n",
    "for i in range(0,x_val.shape[0]):\n",
    "    x_val[i][:] = np.abs(fft(x_val[i][:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are performing normalization\n",
    "transform = StandardScaler()\n",
    "x_train_tr = transform.fit_transform(x_train)\n",
    "x_test_tr = transform.fit_transform(x_test)\n",
    "x_val_tr = transform.fit_transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (4199, 256)\n",
      "(4199, 6)\n",
      "Validation (1800, 256)\n",
      "(1800, 6)\n",
      "Test (3599, 256)\n",
      "(3599, 6)\n"
     ]
    }
   ],
   "source": [
    "#final dimensions of the data\n",
    "print(\"Training\",x_train_tr.shape)\n",
    "print(y_train_hot.shape)\n",
    "print(\"Validation\",x_val_tr.shape)\n",
    "print(y_val_hot.shape)\n",
    "print(\"Test\",x_test_tr.shape)\n",
    "print(y_test_hot.shape)\n",
    "sampling_rate = x_train_tr.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(no_of_classes,sampling_rate):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(64, input_shape=(sampling_rate,), activation = 'relu'))\n",
    "    model.add(Dense(32, activation = 'relu'))\n",
    "    #model.add(Dropout(0.6))\n",
    "    model.add(Dense(16, activation = 'relu'))\n",
    "    #model.add(Dropout(0.6))\n",
    "    model.add(Dense(no_of_classes, activation = 'softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "66/66 [==============================] - 2s 16ms/step - loss: 1.2508 - accuracy: 0.5697 - val_loss: 0.3390 - val_accuracy: 0.9833\n",
      "Epoch 2/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1857 - accuracy: 0.9947 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.0224 - accuracy: 0.9986 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9990 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9970 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9980 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
      "Epoch 9/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.0026 - val_accuracy: 0.9994\n",
      "Epoch 11/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.0026 - val_accuracy: 0.9994\n",
      "Epoch 12/30\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0019 - val_accuracy: 0.9994\n",
      "Epoch 13/30\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.9978 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0017 - val_accuracy: 0.9994\n",
      "Epoch 15/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0031 - val_accuracy: 0.9994\n",
      "Epoch 18/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 4.6771e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9994\n",
      "Epoch 20/30\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 9.3842e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 5.9205e-04 - accuracy: 0.9998 - val_loss: 9.4641e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.0739e-04 - accuracy: 0.9999 - val_loss: 7.7745e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 3.3180e-04 - accuracy: 0.9999 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 8.1401e-04 - accuracy: 0.9997 - val_loss: 8.7501e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 2.1449e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9989\n",
      "Epoch 27/30\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.8176e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.3137e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9994\n",
      "Epoch 29/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.1324e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9994\n",
      "Epoch 30/30\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.1138e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9994\n"
     ]
    }
   ],
   "source": [
    "model = model_training(6,256)\n",
    "history = model.fit(x_train_tr, y_train_hot, batch_size=64, epochs=30, validation_data=(x_val_tr, y_val_hot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 19,158\n",
      "Trainable params: 19,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9925\n",
      "Test accuracy is [0.029626356437802315, 0.9924979209899902]\n"
     ]
    }
   ],
   "source": [
    "pred_acc = model.evaluate(x_test_tr,y_test_hot)\n",
    "print(\"Test accuracy is {}\".format(pred_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = confusion_matrix(y_test_hot.to_numpy().argmax(axis=1), model.predict(x_test_tr).argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[577,   0,  22,   0,   0,   0],\n",
       "       [  0, 599,   1,   0,   0,   0],\n",
       "       [  3,   0, 597,   0,   0,   0],\n",
       "       [  0,   0,   1, 599,   0,   0],\n",
       "       [  0,   0,   0,   0, 600,   0],\n",
       "       [  0,   0,   0,   0,   0, 600]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "to_cm = pd.DataFrame(array, index = [i for i in [\"Type-1\",\"Type-2\",\"Type-3\",\"Type-4\",\"Type-5\",\"Type-6\"]],\n",
    "                  columns = [i for i in [\"Type-1\",\"Type-2\",\"Type-3\",\"Type-4\",\"Type-5\",\"Type-6\"]])\n",
    "plt.figure(figsize = (15,10))\n",
    "sn.heatmap(to_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"model1.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
